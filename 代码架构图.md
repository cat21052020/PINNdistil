# Ψ-NN 代码架构图

## 一、整体架构流程图

```
┌─────────────┐
│  Panel.py   │  ← 主入口，任务调度
└──────┬──────┘
       │
       ▼
┌─────────────────────────────────────────┐
│         Training.model 类                │
│  ┌───────────────────────────────────┐  │
│  │  1. 配置加载 (__init__)           │  │
│  │     - 从CSV读取超参数             │  │
│  │     - 判断是否启用知识蒸馏        │  │
│  └───────────────────────────────────┘  │
│  ┌───────────────────────────────────┐  │
│  │  2. 网格初始化 (mesh_init)        │  │
│  │     - 2D/3D网格或流场数据点       │  │
│  └───────────────────────────────────┘  │
│  ┌───────────────────────────────────┐  │
│  │  3. 训练流程 (train_adam)          │  │
│  │     ├─ 教师网络训练阶段            │  │
│  │     └─ 学生网络蒸馏阶段（可选）    │  │
│  └───────────────────────────────────┘  │
│  ┌───────────────────────────────────┐  │
│  │  4. 结果保存与可视化               │  │
│  │     - model_save()                │  │
│  │     - result_show()               │  │
│  └───────────────────────────────────┘  │
└─────────────────────────────────────────┘
```

## 二、知识蒸馏训练流程

```
┌─────────────────────────────────────────────────────────────┐
│                    训练循环开始                              │
└───────────────────────┬─────────────────────────────────────┘
                        │
        ┌───────────────┴───────────────┐
        │                                │
        ▼                                ▼
┌──────────────────┐          ┌──────────────────┐
│  教师网络训练     │          │  学生网络训练     │
│  (train_steps步)  │          │  (train_steps *  │
│                  │          │   train_ratio步) │
└────────┬─────────┘          └────────┬─────────┘
         │                             │
         ▼                             ▼
┌──────────────────┐          ┌──────────────────┐
│  loss_f: 控制方程 │          │ loss_student_d:   │
│  loss_b: 边界条件 │          │   数据损失        │
│  loss_d: 观测数据 │          │   (含自适应权重) │
│  loss_rgl: 正则化 │          │                  │
└────────┬─────────┘          │ loss_teach:       │
         │                    │   教师-学生差异    │
         ▼                    │                  │
┌──────────────────┐          │ loss_rgl:        │
│  loss = loss_f +  │          │   权重正则化     │
│        loss_b +   │          └────────┬─────────┘
│        loss_d +   │                   │
│        loss_rgl   │                   ▼
└────────┬─────────┘          ┌──────────────────┐
         │                    │ loss_student =    │
         ▼                    │   loss_student_d + │
┌──────────────────┐          │   loss_teach +     │
│  反向传播与优化   │          │   loss_rgl        │
└──────────────────┘          └────────┬─────────┘
                                       │
                                       ▼
                              ┌──────────────────┐
                              │  反向传播与优化   │
                              └──────────────────┘
```

## 三、损失函数计算流程

```
┌─────────────────────────────────────────────────────────────┐
│                     损失函数模块                            │
└─────────────────────────────────────────────────────────────┘

┌──────────────┐    ┌──────────────┐    ┌──────────────┐
│   net_f()    │    │   net_b()    │    │   net_d()    │
│              │    │              │    │              │
│ 控制方程损失  │    │ 边界条件损失  │    │ 数据监督损失  │
│              │    │              │    │              │
│ PDE残差      │    │ 边界约束     │    │ MSE(输出-观测)│
└──────────────┘    └──────────────┘    └──────┬───────┘
                                                │
                        ┌───────────────────────┘
                        │
                        ▼
              ┌─────────────────────┐
              │  知识蒸馏模式        │
              │  (mode='student')    │
              └──────────┬──────────┘
                         │
        ┌────────────────┴────────────────┐
        │                                 │
        ▼                                 ▼
┌──────────────────┐          ┌──────────────────┐
│ k_value = 0      │          │ k_value > 0      │
│                  │          │                  │
│ 标准数据损失      │          │ 自适应权重损失    │
│ loss = MSE(...)  │          │ fai = 1 - tanh(  │
│                  │          │   k * |t-s|)     │
│                  │          │ loss = (1-fai) * │
│                  │          │   MSE(...)       │
└──────────────────┘          └──────────────────┘

┌──────────────┐    ┌──────────────┐
│ net_teach()  │    │ net_rgl()    │
│              │    │              │
│ 知识蒸馏损失  │    │ 正则化损失    │
│              │    │              │
│ MSE(教师-学生)│    │ L1/L2/GrOWL │
└──────────────┘    └──────────────┘
```

## 四、网络结构层次

```
┌─────────────────────────────────────────────────────────────┐
│                      网络结构模块                            │
└─────────────────────────────────────────────────────────────┘

基础网络：
┌──────────────────┐
│   PINN.py        │
│                  │
│ 标准MLP结构       │
│ Input → Hidden → │
│ Output           │
│ (Tanh激活)       │
└──────────────────┘
         │
         ├─────────────────┬─────────────────┬──────────────┐
         │                 │                 │              │
         ▼                 ▼                 ▼              ▼
┌──────────────┐  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐
│PsiNN_burgers │  │PsiNN_laplace │  │PsiNN_poisson │  │PsiNN_flow    │
│              │  │              │  │              │  │              │
│专用网络结构   │  │专用网络结构   │  │专用网络结构   │  │专用网络结构   │
│              │  │              │  │              │  │              │
│隐式嵌入物理   │  │隐式嵌入物理   │  │隐式嵌入物理   │  │隐式嵌入物理   │
│对称性        │  │对称性        │  │对称性        │  │对称性        │
└──────────────┘  └──────────────┘  └──────────────┘  └──────────────┘
```

## 五、数据流向

```
配置文件 (CSV)
    │
    ▼
┌─────────────────┐
│  Config加载     │ → 超参数字典
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  数据库加载      │ → 观测数据
│  (Database/)    │
└────────┬────────┘
         │
         ├─────────────────┬─────────────────┐
         │                 │                 │
         ▼                 ▼                 ▼
┌──────────────┐  ┌──────────────┐  ┌──────────────┐
│  网格点生成   │  │  边界点生成   │  │  观测点加载   │
│  (mesh_init) │  │  (net_b)     │  │  (net_d)     │
└──────┬───────┘  └──────┬───────┘  └──────┬───────┘
       │                 │                 │
       └─────────────────┴─────────────────┘
                         │
                         ▼
              ┌──────────────────────┐
              │   网络前向传播        │
              │   (forward)          │
              └──────────┬───────────┘
                         │
                         ▼
              ┌──────────────────────┐
              │   损失计算            │
              │   (net_f/net_b/net_d)│
              └──────────┬───────────┘
                         │
                         ▼
              ┌──────────────────────┐
              │   反向传播与优化      │
              │   (backward/step)    │
              └──────────────────────┘
```

## 六、知识蒸馏机制详解

```
┌─────────────────────────────────────────────────────────────┐
│                  知识蒸馏机制 (k_value > 0)                 │
└─────────────────────────────────────────────────────────────┘

观测点附近：
┌─────────────────────────────────────┐
│ |teacher - monitor| 较小            │
│ fai = 1 - tanh(k * 小值) ≈ 0        │
│                                     │
│ loss_d = (1-0) * MSE(student-monitor)│
│       ≈ MSE(student-monitor)        │
│                                     │
│ → 主要学习观测值                     │
└─────────────────────────────────────┘

远离观测点：
┌─────────────────────────────────────┐
│ |teacher - monitor| 较大            │
│ fai = 1 - tanh(k * 大值) ≈ 1        │
│                                     │
│ loss_d = (1-1) * MSE(...) ≈ 0      │
│                                     │
│ → 主要学习教师输出                   │
│   (通过 loss_teach)                 │
└─────────────────────────────────────┘
```

## 七、结构提取流程

```
训练完成的学生网络
    │
    ▼
┌─────────────────┐
│  加载权重文件    │ (.pth)
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  权重聚类分析    │ (pic_Parameter.ipynb)
│  - 层次聚类      │
│  - 识别聚类中心  │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  结构模式识别    │
│  - 字母代号表示  │ (A, B, -A, -B)
│  - 对称性分析    │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  可视化输出      │
│  - 权重分布图    │
│  - 聚类结果图    │
└─────────────────┘
```

## 八、模块依赖关系

```
Panel.py
  │
  └── Training.model
       │
       ├── PINN.Net ──────────────┐
       │                          │
       ├── PsiNN_*.Net ────────────┤──→ 网络结构
       │                          │
       ├── PINN_post_*.Net ───────┘
       │
       ├── SingleVis.Vis ──────────→ 单模型可视化
       │
       └── GroupVis.Vis ───────────→ 多模型对比可视化
```

## 九、配置文件结构

```
Config/
├── Burgers_inv_distill_EXP.csv  ← 知识蒸馏配置
│   ├── model: PINN
│   ├── hidden_layers_group: "1,1,2"
│   ├── hidden_layers_group_student: "1,1,1"
│   ├── k_value: 0
│   └── train_ratio: 2
│
└── Burgers_inv_EXP.csv  ← 对比实验配置
    ├── model: PINN PINN_post_minus PsiNN_burgers
    └── ...
```

## 十、输出结果结构

```
Results/
└── {ques_name}_{ini_num}/
    ├── Models/              ← 模型权重
    │   ├── {model}_step_{iter}.pth
    │   └── {model}_student_step_{iter}.pth
    │
    ├── Loss/                ← 损失数据
    │   ├── {model}_loss.csv
    │   └── {model}_loss_student.csv
    │
    ├── Parameters/          ← 参数演化（逆问题时）
    │   └── {model}_paras.csv
    │
    ├── Figures/             ← 可视化图片
    │   ├── field_2d.png
    │   ├── loss_curve.png
    │   └── ...
    │
    └── Cluster/             ← 聚类结果（可选）
        └── {layer}_distribution.png
```

---

**快速导航**：
- 详细文档：`代码框架梳理.md`
- 架构图：本文档
- 代码入口：`Panel.py`
- 核心模块：`Module/Training.py`

